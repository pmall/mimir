{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M\u00cdMIR: Target-Conditioned Peptide Design\n",
        "\n",
        "Train the M\u00cdMIR model on Google Colab using ESM-3 and LoRA for target-specific peptide generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "# Look for 'Tesla T4' (Free Tier, 16GB VRAM) or 'A100' (Pro, 40GB+ VRAM).\n",
        "# If you have a T4, you might need to reduce batch_size if you hit OOM.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Clone Repository & Install Dependencies\n",
        "We clone the M\u00cdMIR repository and install the specific dependencies required for ESM-3 and LoRA fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef7f790",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Repository URL\n",
        "REPO_URL = \"https://github.com/pmall/mimir.git\"\n",
        "\n",
        "!git clone $REPO_URL\n",
        "%cd mimir\n",
        "\n",
        "# Install dependencies from pyproject.toml\n",
        "!pip install -e . --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Authenticate with Hugging Face\n",
        "ESM-3 weights are gated. You must authenticate to download them. Ensure your token has access to `evolutionaryscale/esm3-sm-open-v1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!hf auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Setup & Verification\n",
        "We download the ESM-3 weights and perform a quick load test to ensure the environment is correctly configured before starting the heavy training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download ESM-3 weights\n",
        "!python scripts/download_weights.py\n",
        "\n",
        "# Verify successful load\n",
        "import esm\n",
        "from esm.models.esm3 import ESM3\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "print(f\"ESM Version: {esm.__version__}\")\n",
        "try:\n",
        "    # Load model to verify weights are present\n",
        "    model = ESM3.from_pretrained(\"esm3_sm_open_v1\")\n",
        "    print(\"\u2705 ESM-3 model loaded successfully.\")\n",
        "    \n",
        "    # CRITICAL: Delete model and clear cache to free GPU memory for the training script\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"\ud83e\uddf9 GPU memory cleared. Ready for training.\")\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Failed to load ESM-3: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload Dataset\n",
        "Upload your `mapping_dataset.csv` file containing the peptide-target pairs. This file is critical for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "print(\"Please upload your 'mapping_dataset.csv' file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Received file \"{filename}\"')\n",
        "    # We rename it to mapping_dataset.csv for the training script\n",
        "    target_path = 'data/mapping_dataset.csv'\n",
        "    shutil.move(filename, target_path)\n",
        "    print(f\"Moved {filename} to {target_path}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-Tune ESM-3\n",
        "\n",
        "We now commence training. \n",
        "\n",
        "### Training Configuration\n",
        "- **`epochs`**: **100**. Target run length for this session.\n",
        "- **`batch_size`**: **64**. Adjusted for Colab T4 stability.\n",
        "- **`masking_boost_ratio`**: **0.5**. Boosts gradient for difficult samples.\n",
        "- **`lr`**: **1e-4**. Standard LoRA learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python scripts/train.py --epochs 100 --batch_size 64 --masking_boost_ratio 0.5 --lr 1e-4 --dataset data/mapping_dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Download Model\n",
        "Download the **best** model (lowest average true loss) saved during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zip the BEST model\n",
        "!zip -r mimir_best_model.zip checkpoints/best_model/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('mimir_best_model.zip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}